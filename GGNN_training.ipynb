{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09fdda4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'qsprpred.extra.gpu.models.gdnn' from '/home/brokesm/anaconda3/lib/python3.12/site-packages/qsprpred/extra/gpu/models/gdnn.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import pandas as pd \n",
    "import json\n",
    "from qsprpred.data import QSPRDataset, RandomSplit\n",
    "from qsprpred.models import QSPRModel\n",
    "from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "from qsprpred.data.descriptors.sets import SmilesDesc\n",
    "from qsprpred.models import OptunaOptimization, TestSetAssessor, CrossValAssessor, SklearnModel\n",
    "from qsprpred.data.sampling.splits import DataSplit\n",
    "from qsprpred.data.processing.data_filters import RepeatsFilter, CategoryFilter\n",
    "from qsprpred.models import EarlyStoppingMode\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from qsprpred.extra.gpu.models.chemprop import ChempropModel\n",
    "\n",
    "from qsprpred.extra.gpu.models.dnn import DNNModel\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from typing import Iterable, List, Tuple\n",
    "\n",
    "from typing import Literal\n",
    "import sys\n",
    "#sys.path.insert(0, '/home/ubuntu/implementation/QSPRpred')\n",
    "\n",
    "#import qsprpred.extra.gpu.models.gdnn as gdnn_module\n",
    "#from importlib import reload\n",
    "#\n",
    "#reload(gdnn_module)\n",
    "\n",
    "modname = 'qsprpred.extra.gpu.models.gdnn'\n",
    "if modname in sys.modules:\n",
    "    del sys.modules[modname]\n",
    "\n",
    "import qsprpred.extra.gpu.models.gdnn as gdnn_module\n",
    "from qsprpred.extra.gpu.models.gdnn import GGNN\n",
    "importlib.reload(gdnn_module)\n",
    "\n",
    "#from qsprpred.extra.gpu.models.gdnn import DNNModel, GGNN\n",
    "#print(DNNModel.__init__.__code__.co_varnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac295870",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a folder structure\n",
    "\n",
    "os.makedirs(\"./output/models\", exist_ok=True)\n",
    "os.makedirs(\"./output/benchmarking/data\", exist_ok=True)\n",
    "os.makedirs(\"./output/optimization/data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96c0a1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a customsplit class\n",
    "# inherits from datasplit\n",
    "# input - QSPRDataset ids\n",
    "# output - (train,test) splits\n",
    "\n",
    "class CustomSplit(DataSplit):\n",
    "\n",
    "    def __init__(self, test_ids: list[list[str]]):\n",
    "        super().__init__()\n",
    "        self.test_ids = test_ids\n",
    "\n",
    "    def split(\n",
    "        self,\n",
    "        X: np.ndarray | pd.DataFrame, \n",
    "        y: np.ndarray | pd.DataFrame | pd.Series\n",
    "    ) -> Iterable[tuple[list[int], list[int]]]:\n",
    "        \"\"\"Uses only the specified IDs from the data set as test set\n",
    "        Returns an iterator of training and test split indices, \n",
    "        just like a scikit learn splitter would.\n",
    "        \"\"\"\n",
    "        splits = []\n",
    "        for test_ids in self.test_ids:\n",
    "            test = np.where(X.index.isin(test_ids))[0]\n",
    "            train = np.where(~X.index.isin(test_ids))[0]\n",
    "            splits.append((train, test))\n",
    "        return splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7065586f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ids(dataset_name, keep_ids):\n",
    "    return [f\"{dataset_name}_{\"0\" * (4 - len(str(id)))}{id}\" for id in keep_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "046e884e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loading(\n",
    "        target:Literal[\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"], \n",
    "        purpose:Literal[\"ForOptimization\",\"ForBenchmarking\"],\n",
    "        model:QSPRModel | None = None,\n",
    "        save = True\n",
    "        ) -> Tuple[QSPRDataset, List, List, List]:\n",
    "\n",
    "    dataset_name = f\"{purpose}_{target}\"\n",
    "    store_dir = f\"./output/{purpose[3:].lower()}/data\"\n",
    "\n",
    "    dataset = QSPRDataset.fromTableFile(\n",
    "        filename=f\"./papyrus_datasets/{target}.csv\",\n",
    "        sep=\",\",\n",
    "        store_dir=store_dir,\n",
    "        name=dataset_name,\n",
    "        target_props=[{\"name\": \"Y\", \"task\": \"SINGLECLASS\", \"th\":\"precomputed\"}],\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    if model is not None:\n",
    "        if model.supportsEarlyStopping:\n",
    "            # In case of GNNs (both support early stopping) add SmilesDesc as descriptors\n",
    "            dataset.addDescriptors([SmilesDesc()])\n",
    "        else:\n",
    "            # In case of XGB (doesn't support early stopping) add MorganFP with default parameters as descriptors\n",
    "            dataset.addDescriptors([MorganFP()])\n",
    "\n",
    "    if save:\n",
    "        dataset.save()\n",
    "    \n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2e7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_optimization(\n",
    "        model:QSPRModel, \n",
    "        dataset:QSPRDataset, \n",
    "        search_space:dict, \n",
    "        scoring:str, \n",
    "        val_ids:List,\n",
    "        test_ids:List\n",
    "        ):\n",
    "    # opravit, prvy split CVA je rozdelenie povodneho datasetu na train/test\n",
    "    # nasledny dataset split bude na train/val (val set je iba na early stopping v ramci CVA)\n",
    "    # Uz asi hotovo\n",
    "    gridsearcher = OptunaOptimization(\n",
    "        n_trials=100,\n",
    "        param_grid=search_space,\n",
    "        model_assessor=CrossValAssessor(scoring=scoring, split=CustomSplit([test_ids])),\n",
    "    )\n",
    "\n",
    "    dataset.prepareDataset(\n",
    "        split=CustomSplit([val_ids])\n",
    "    )\n",
    "    gridsearcher.optimize(model, dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f92aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsprpred - WARNING - Random state supplied, but alg <class 'qsprpred.extra.gpu.models.gdnn.GGNN'> does not support it. Ignoring this setting.\n"
     ]
    }
   ],
   "source": [
    "model_ggnn = gdnn_module.DNNModel(\n",
    "    base_dir='./output/models/GGNN',\n",
    "    name='GGNNModel',\n",
    "    parameters={'n_epochs': 100,\n",
    "                'out_feats': 74,          # 74-256 for example\n",
    "                'in_feats': 74,\n",
    "                'steps': 3,\n",
    "                'n_hidden_layers': 2,\n",
    "                'dropout_rate': 0.2,\n",
    "                \"optim_lr\":1e-4,\n",
    "                \"batch_size\":128,\n",
    "               },\n",
    "    tol=0.01,\n",
    "    random_state=42,\n",
    "    patience=50\n",
    ")\n",
    "\n",
    "search_space_ggnn = {\n",
    "    \"n_hidden_layers\": [\"int\", 1, 6],\n",
    "    \"dropout_rate\": [\"float\", 0.05, 0.5],\n",
    "    \"steps\": [\"int\", 2, 5],\n",
    "    \"batch_size\": [\"categorical\", [32,64,128,256]],\n",
    "    'out_feats': [\"int\",74,256],\n",
    "    'in_feats': [\"int\",74,74],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e18be5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_chemprop = ChempropModel(\n",
    "    base_dir='./output/models/Chemprop',\n",
    "    name='ChempropModel',\n",
    "    parameters={\n",
    "        \"epochs\": 5,\n",
    "        \"loss_function\":'binary_cross_entropy'\n",
    "        },\n",
    "    quiet_logger=False\n",
    ")\n",
    "\n",
    "search_space_chemprop = {\n",
    "    \"epochs\": [\"int\", 1,5],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0b22915",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb = SklearnModel(\n",
    "            name=\"XGBModel\",\n",
    "            alg=GradientBoostingClassifier,\n",
    "            base_dir=\"./output/models/XGB\",\n",
    "            parameters={\n",
    "                \"max_depth\":2,\n",
    "                \"n_estimators\":10\n",
    "            }\n",
    "        )\n",
    "\n",
    "search_space_xgb = {\n",
    "    \"max_depth\": [\"int\", 2, 10],\n",
    "    \"n_estimators\": [\"int\", 5,500]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3211fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_loader(\n",
    "        target:Literal[\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"], \n",
    "        split_type:Literal[\"random\", \"cluster\", \"aggregate_cluster\"],\n",
    "        seed,\n",
    "        purpose:Literal[\"ForBenchmarking\",\"ForOptimization\"]\n",
    "        ):\n",
    "    seed = str(seed)\n",
    "\n",
    "    with open(f\"./papyrus_datasets/{split_type}_split.json\") as file:\n",
    "        json_file = file.read()\n",
    "\n",
    "    split = json.loads(json_file)\n",
    "    \n",
    "    train_ids = split[split_type][target][seed][\"train\"]\n",
    "    val_ids = split[split_type][target][seed][\"valid\"]\n",
    "    test_ids = split[split_type][target][seed][\"test\"]\n",
    "\n",
    "    train_ids = select_ids(f\"{purpose}_{target}\",list(train_ids))\n",
    "    val_ids = select_ids(f\"{purpose}_{target}\",list(val_ids))\n",
    "    test_ids = select_ids(f\"{purpose}_{target}\",list(test_ids))\n",
    "\n",
    "    return train_ids, val_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e77e3c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(\n",
    "        target:Literal[\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"],\n",
    "        split:Literal[\"random\",\"cluster\",\"aggregate_cluster\"],\n",
    "        model:QSPRModel,\n",
    "        search_space:dict,\n",
    "        seed = 0\n",
    "        ):\n",
    "\n",
    "        dataset = data_loading(target,model=model, purpose=\"ForOptimization\")\n",
    "        train_ids, val_ids, test_ids = set_loader(target,split,seed,purpose=\"ForOptimization\")\n",
    "        #selected_ids = train_ids + val_ids\n",
    "        #dataset.prepareDataset(data_filters=[CategoryFilter(name=\"QSPRID\", values=selected_ids, keep=True)])\n",
    "        \n",
    "        hyperparameter_optimization(model=model, dataset=dataset, search_space=search_space, scoring=\"matthews_corrcoef\", val_ids=val_ids, test_ids=test_ids)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ba61c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"]\n",
    "splits = [\"random\",\"cluster\", \"aggregate_cluster\"]\n",
    "models = [model_xgb, model_ggnn, model_chemprop]\n",
    "search_spaces = [search_space_xgb, search_space_ggnn, search_space_chemprop]\n",
    "\n",
    "for target in targets:\n",
    "    for split in splits:\n",
    "        for model, search_space in zip(models, search_spaces):\n",
    "            model.name += f\"_{target}_{split}\"\n",
    "            optimize(target = target, split = split, model = model, search_space = search_space)\n",
    "            model.name = model.name.split(\"_\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eedd70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_params(\n",
    "        target:Literal[\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"], \n",
    "        split_type:Literal[\"random\",\"cluster\",\"aggregate_cluster\"],\n",
    "        model:Literal[\"XGB\",\"GGNN\",\"Chemprop\"]\n",
    "    ):\n",
    "\n",
    "    with open(f\"./output/models/{model}/{model}Model_{target}_{split_type}/{model}Model_{target}_{split_type}_meta.json\") as f:\n",
    "        params = f.read()\n",
    "\n",
    "    params = json.loads(params)\n",
    "    return params[\"py/state\"][\"parameters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00d00218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_benchmarking(dataset:QSPRDataset,descriptors, chemprop=False):\n",
    "\n",
    "    dataset.addDescriptors([descriptors])\n",
    "\n",
    "    if chemprop:\n",
    "        # binary cross entropy loss cannot deal with target variable being of type int\n",
    "        dataset.transformProperties([\"Y\",\"Y_original\"],transformer=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "68b45a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    target:Literal[\"P00918\",\"P03372\",\"P04637\",\"P08684\",\"P14416\",\"P22303\",\"P42336\",\"Q12809\",\"Q16637\",\"Q9Y468\"],\n",
    "    split_type:Literal[\"random\",\"cluster\",\"aggregate_cluster\"]\n",
    "):\n",
    "    os.makedirs(f\"./output/benchmarking/{target}/{split_type}\", exist_ok=True)\n",
    "\n",
    "    # save the dataset corresponding to a given target\n",
    "    data_loading(target,purpose=\"ForBenchmarking\")\n",
    "    \n",
    "    results = {\n",
    "        \"model\":[],\n",
    "        \"metric\":[],\n",
    "        \"score\":[]\n",
    "    }\n",
    "    for metric in [\"matthews_corrcoef\",\"f1\",\"recall\",\"precision\",\"roc_auc\"]:\n",
    "        for seed in range(1,21):\n",
    "            # get the ids for training, validation and test sets for a given combination of target + split + seed\n",
    "            _, val_ids, test_ids = set_loader(target,split_type,seed=seed, purpose=\"ForBenchmarking\")\n",
    "            dataset_path = f\"./output/benchmarking/data/ForBenchmarking_{target}/ForBenchmarking_{target}_meta.json\"\n",
    "            \n",
    "            dataset_xgb = QSPRDataset.fromFile(dataset_path)\n",
    "            dataset_ggnn = QSPRDataset.fromFile(dataset_path)\n",
    "            dataset_chemprop = QSPRDataset.fromFile(dataset_path)\n",
    "\n",
    "\n",
    "            prepare_for_benchmarking(dataset_xgb,MorganFP())\n",
    "            prepare_for_benchmarking(dataset_ggnn,SmilesDesc())\n",
    "            prepare_for_benchmarking(dataset_chemprop,SmilesDesc(), chemprop=True)\n",
    "\n",
    "            model_xgb.parameters = get_model_params(target,split_type,\"XGB\")\n",
    "            model_ggnn.parameters = get_model_params(target,split_type,\"GGNN\")\n",
    "            model_chemprop.parameters = get_model_params(target,split_type,\"Chemprop\")\n",
    "\n",
    "            proba = True\n",
    "            if metric == \"matthews_corrcoef\":\n",
    "                proba = False\n",
    "\n",
    "            dataset_xgb.prepareDataset(split = CustomSplit([test_ids]))\n",
    "            xgb_score = TestSetAssessor(scoring=metric, use_proba=proba)(model_xgb, dataset_xgb)\n",
    "            results[\"model\"].append(\"XGB\")\n",
    "            results[\"metric\"].append(metric)\n",
    "            results[\"score\"].append(xgb_score.item())\n",
    "\n",
    "\n",
    "            # Tu mozno pouzit iba CVA, kde na val mnozine najdem best epoch pomocou early stopping\n",
    "            # Na test mnozine v ramci toho isteho CVA vypocitam skore\n",
    "            # Uz opravene\n",
    "            ggnn_score = CrossValAssessor(\n",
    "                scoring=metric,\n",
    "                use_proba=proba,\n",
    "                mode=EarlyStoppingMode.RECORDING,\n",
    "                split=CustomSplit([test_ids]))(model_ggnn, dataset_ggnn,split=CustomSplit([val_ids]))\n",
    "            print(f\"Best epoch found for GGNN: {model_ggnn.earlyStopping.optimalEpochs}\")\n",
    "            results[\"model\"].append(\"GGNN\")\n",
    "            results[\"metric\"].append(metric)\n",
    "            results[\"score\"].append(ggnn_score.item())\n",
    "\n",
    "            chemprop_score = CrossValAssessor(\n",
    "                scoring=metric,\n",
    "                use_proba=proba,\n",
    "                mode=EarlyStoppingMode.RECORDING,\n",
    "                split=CustomSplit([test_ids]))(model_chemprop, dataset_chemprop,split=CustomSplit([test_ids]))\n",
    "            print(f\"Best epoch found for Chemprop: {model_chemprop.earlyStopping.optimalEpochs}\")\n",
    "            results[\"model\"].append(\"Chemprop\")\n",
    "            results[\"metric\"].append(metric)\n",
    "            results[\"score\"].append(chemprop_score.item())\n",
    "            \n",
    "    pd.DataFrame(results).to_csv(f\"./output/benchmarking/{target}/{split_type}/results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0383e426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Y</th>\n",
       "      <th>QSPRID</th>\n",
       "      <th>Y_original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>QSPRID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ChempropTutorialDataset_0000</th>\n",
       "      <td>CC(=O)OCC1OC(NS(=O)(=O)NO)C=CC1OC(C)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>ChempropTutorialDataset_0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropTutorialDataset_0001</th>\n",
       "      <td>CC(=O)OCC1OC(CC(=O)C=Cc2cccc(O)c2)C(OC(C)=O)C(...</td>\n",
       "      <td>0</td>\n",
       "      <td>ChempropTutorialDataset_0001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropTutorialDataset_0002</th>\n",
       "      <td>COc1ccc(CNc2ccc(S(N)(=O)=O)cc2)cc1</td>\n",
       "      <td>1</td>\n",
       "      <td>ChempropTutorialDataset_0002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropTutorialDataset_0003</th>\n",
       "      <td>CN(C)C=Nc1ncnc2c1ncn2CC(=O)Nc1ccc(S(N)(=O)=O)cc1</td>\n",
       "      <td>1</td>\n",
       "      <td>ChempropTutorialDataset_0003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChempropTutorialDataset_0004</th>\n",
       "      <td>Cc1sc(-c2noc(N)c2S(N)(=O)=O)cc1S(N)(=O)=O</td>\n",
       "      <td>1</td>\n",
       "      <td>ChempropTutorialDataset_0004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                         SMILES  \\\n",
       "QSPRID                                                                            \n",
       "ChempropTutorialDataset_0000             CC(=O)OCC1OC(NS(=O)(=O)NO)C=CC1OC(C)=O   \n",
       "ChempropTutorialDataset_0001  CC(=O)OCC1OC(CC(=O)C=Cc2cccc(O)c2)C(OC(C)=O)C(...   \n",
       "ChempropTutorialDataset_0002                 COc1ccc(CNc2ccc(S(N)(=O)=O)cc2)cc1   \n",
       "ChempropTutorialDataset_0003   CN(C)C=Nc1ncnc2c1ncn2CC(=O)Nc1ccc(S(N)(=O)=O)cc1   \n",
       "ChempropTutorialDataset_0004          Cc1sc(-c2noc(N)c2S(N)(=O)=O)cc1S(N)(=O)=O   \n",
       "\n",
       "                              Y                        QSPRID  Y_original  \n",
       "QSPRID                                                                     \n",
       "ChempropTutorialDataset_0000  1  ChempropTutorialDataset_0000           1  \n",
       "ChempropTutorialDataset_0001  0  ChempropTutorialDataset_0001           0  \n",
       "ChempropTutorialDataset_0002  1  ChempropTutorialDataset_0002           1  \n",
       "ChempropTutorialDataset_0003  1  ChempropTutorialDataset_0003           1  \n",
       "ChempropTutorialDataset_0004  1  ChempropTutorialDataset_0004           1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import os\n",
    "\n",
    "# from qsprpred.data import QSPRDataset, RandomSplit\n",
    "# from qsprpred.data.descriptors.fingerprints import MorganFP\n",
    "# from qsprpred.data.descriptors.sets import SmilesDesc\n",
    "\n",
    "# # Create dataset\n",
    "# dataset = QSPRDataset.fromTableFile(\n",
    "#     filename=\"./papyrus_datasets/P00918.csv\",\n",
    "#     sep=\",\",\n",
    "#     store_dir=\"./tutorial_output/data\",\n",
    "#     name=\"ChempropTutorialDataset\",\n",
    "#     target_props=[{\"name\": \"Y\", \"task\": \"SINGLECLASS\", \"th\":\"precomputed\"}],\n",
    "#     random_state=42\n",
    "# )\n",
    "\n",
    "# # calculate compound features and split dataset into train and test\n",
    "# feature_calculators = [SmilesDesc()]\n",
    "# dataset.prepareDataset(\n",
    "#     split=RandomSplit(test_fraction=0.2, dataset=dataset),\n",
    "#     feature_calculators=feature_calculators)\n",
    "\n",
    "# dataset.getDF().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c092ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qsprpred - WARNING - Existing data set found, but also found a data frame in store. Refusing to overwrite data. If you want to overwrite data in store, set overwrite=True.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGNN updated\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'out_feats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m splits:\n\u001b[0;32m----> 3\u001b[0m         benchmark(target,split)\n",
      "Cell \u001b[0;32mIn[20], line 48\u001b[0m, in \u001b[0;36mbenchmark\u001b[0;34m(target, split_type)\u001b[0m\n\u001b[1;32m     42\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(xgb_score\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# Tu mozno pouzit iba CVA, kde na val mnozine najdem best epoch pomocou early stopping\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Na test mnozine v ramci toho isteho CVA vypocitam skore\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Uz opravene\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m ggnn_score \u001b[38;5;241m=\u001b[39m CrossValAssessor(\n\u001b[1;32m     49\u001b[0m     scoring\u001b[38;5;241m=\u001b[39mmetric,\n\u001b[1;32m     50\u001b[0m     use_proba\u001b[38;5;241m=\u001b[39mproba,\n\u001b[1;32m     51\u001b[0m     mode\u001b[38;5;241m=\u001b[39mEarlyStoppingMode\u001b[38;5;241m.\u001b[39mRECORDING,\n\u001b[1;32m     52\u001b[0m     split\u001b[38;5;241m=\u001b[39mCustomSplit([test_ids]))(model_ggnn, dataset_ggnn,split\u001b[38;5;241m=\u001b[39mCustomSplit([val_ids]))\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest epoch found for GGNN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_ggnn\u001b[38;5;241m.\u001b[39mearlyStopping\u001b[38;5;241m.\u001b[39moptimalEpochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     54\u001b[0m results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGGNN\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/qsprpred/models/assessment/methods.py:211\u001b[0m, in \u001b[0;36mCrossValAssessor.__call__\u001b[0;34m(self, model, ds, save, parameters, monitor, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m monitor\u001b[38;5;241m.\u001b[39monFoldStart(\n\u001b[1;32m    208\u001b[0m     fold\u001b[38;5;241m=\u001b[39mi, X_train\u001b[38;5;241m=\u001b[39mX_train, y_train\u001b[38;5;241m=\u001b[39my_train, X_test\u001b[38;5;241m=\u001b[39mX_test, y_test\u001b[38;5;241m=\u001b[39my_test\n\u001b[1;32m    209\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;66;03m# fit model\u001b[39;00m\n\u001b[0;32m--> 211\u001b[0m crossval_estimator \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mloadEstimator(evalparams)\n\u001b[1;32m    212\u001b[0m model_fit \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    213\u001b[0m     X_train,\n\u001b[1;32m    214\u001b[0m     y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    219\u001b[0m )\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# make predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/qsprpred/extra/gpu/models/gdnn.py:516\u001b[0m, in \u001b[0;36mDNNModel.loadEstimator\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUninitialized model.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;66;03m# initialize model - GGNN here\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malg(\n\u001b[1;32m    517\u001b[0m     n_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnDim,\n\u001b[1;32m    518\u001b[0m     n_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnClass,\n\u001b[1;32m    519\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice),\n\u001b[1;32m    520\u001b[0m     gpus\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgpus,\n\u001b[1;32m    521\u001b[0m     \u001b[38;5;66;03m#FIXED is_reg\u001b[39;00m\n\u001b[1;32m    522\u001b[0m     \u001b[38;5;66;03m#is_reg=False,#self.task == ModelTasks.REGRESSION,\u001b[39;00m\n\u001b[1;32m    523\u001b[0m     is_reg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtask \u001b[38;5;241m==\u001b[39m ModelTasks\u001b[38;5;241m.\u001b[39mREGRESSION,\n\u001b[1;32m    524\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatience,\n\u001b[1;32m    525\u001b[0m     tol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtol,\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;66;03m#FIXED don't accept any parameters\u001b[39;00m\n\u001b[1;32m    527\u001b[0m     parameters\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    528\u001b[0m )\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    529\u001b[0m \u001b[38;5;66;03m# set parameters if available and return\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;66;03m#FIXED load parameters\u001b[39;00m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;66;03m# new_parameters = self.getParameters(params)\u001b[39;00m\n\u001b[1;32m    532\u001b[0m \u001b[38;5;66;03m# if new_parameters is not None:\u001b[39;00m\n\u001b[1;32m    533\u001b[0m \u001b[38;5;66;03m#    estimator.set_params(**new_parameters)\u001b[39;00m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m estimator\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/qsprpred/extra/gpu/models/gdnn.py:62\u001b[0m, in \u001b[0;36mGGNN.__init__\u001b[0;34m(self, n_dim, device, gpus, is_reg, patience, tol, parameters, n_class)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_steps \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_etypes \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_etypes\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_feats \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout_feats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_lr \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptim__lr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_wd \u001b[38;5;241m=\u001b[39m parameters[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moptim__weight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'out_feats'"
     ]
    }
   ],
   "source": [
    "for target in targets:\n",
    "    for split in splits:\n",
    "        benchmark(target,split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33bf121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'C:\\\\Users\\\\marti\\\\AppData\\\\Roaming\\\\Python\\\\Python312\\\\site-packages'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
